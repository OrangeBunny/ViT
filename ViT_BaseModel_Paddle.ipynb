{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisualTransformer(\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (patch_embedding): Conv2D(3, 768, kernel_size=[16, 16], stride=[16, 16], data_format=NCHW)\n",
      "    (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (layers): LayerList(\n",
      "      (0): EncoderLayer(\n",
      "        (attn_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
      "          (softmax): Softmax(axis=-1)\n",
      "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "        )\n",
      "        (mlp_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (act): GELU(approximate=False)\n",
      "          (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (attn_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
      "          (softmax): Softmax(axis=-1)\n",
      "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "        )\n",
      "        (mlp_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (act): GELU(approximate=False)\n",
      "          (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (attn_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
      "          (softmax): Softmax(axis=-1)\n",
      "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
      "        )\n",
      "        (mlp_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
      "          (act): GELU(approximate=False)\n",
      "          (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1000, dtype=float32)\n",
      ")\n",
      "----------------------------------------------------------------------------\n",
      "  Layer (type)       Input Shape          Output Shape         Param #    \n",
      "============================================================================\n",
      "    Conv2D-1      [[4, 3, 224, 224]]    [4, 768, 14, 14]       590,592    \n",
      "PatchEmbedding-1  [[4, 3, 224, 224]]     [4, 197, 768]         152,064    \n",
      "  LayerNorm-1      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "    Linear-1       [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \n",
      "   Softmax-1      [[4, 4, 197, 197]]    [4, 4, 197, 197]          0       \n",
      "    Linear-2       [[4, 197, 768]]       [4, 197, 768]         590,592    \n",
      "  Attention-1      [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "  LayerNorm-2      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "    Linear-3       [[4, 197, 768]]       [4, 197, 3072]       2,362,368   \n",
      "     GELU-1        [[4, 197, 3072]]      [4, 197, 3072]           0       \n",
      "   Dropout-2       [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "    Linear-4       [[4, 197, 3072]]      [4, 197, 768]        2,360,064   \n",
      "     Mlp-1         [[4, 197, 768]]       [4, 197, 768]            0       \n",
      " EncoderLayer-1    [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "  LayerNorm-3      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "    Linear-5       [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \n",
      "   Softmax-2      [[4, 4, 197, 197]]    [4, 4, 197, 197]          0       \n",
      "    Linear-6       [[4, 197, 768]]       [4, 197, 768]         590,592    \n",
      "  Attention-2      [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "  LayerNorm-4      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "    Linear-7       [[4, 197, 768]]       [4, 197, 3072]       2,362,368   \n",
      "     GELU-2        [[4, 197, 3072]]      [4, 197, 3072]           0       \n",
      "   Dropout-3       [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "    Linear-8       [[4, 197, 3072]]      [4, 197, 768]        2,360,064   \n",
      "     Mlp-2         [[4, 197, 768]]       [4, 197, 768]            0       \n",
      " EncoderLayer-2    [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "  LayerNorm-5      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "    Linear-9       [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \n",
      "   Softmax-3      [[4, 4, 197, 197]]    [4, 4, 197, 197]          0       \n",
      "   Linear-10       [[4, 197, 768]]       [4, 197, 768]         590,592    \n",
      "  Attention-3      [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "  LayerNorm-6      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "   Linear-11       [[4, 197, 768]]       [4, 197, 3072]       2,362,368   \n",
      "     GELU-3        [[4, 197, 3072]]      [4, 197, 3072]           0       \n",
      "   Dropout-4       [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "   Linear-12       [[4, 197, 3072]]      [4, 197, 768]        2,360,064   \n",
      "     Mlp-3         [[4, 197, 768]]       [4, 197, 768]            0       \n",
      " EncoderLayer-3    [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "  LayerNorm-7      [[4, 197, 768]]       [4, 197, 768]          1,536     \n",
      "   Encoder-1       [[4, 197, 768]]       [4, 197, 768]            0       \n",
      "   Linear-13          [[4, 768]]           [4, 1000]           769,000    \n",
      "============================================================================\n",
      "Total params: 22,769,896\n",
      "Trainable params: 22,769,896\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 295.87\n",
      "Params size (MB): 86.86\n",
      "Estimated Total Size (MB): 385.02\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ViT Base Model\n",
    "# Author: Cheng XU\n",
    "# Reference: PaddleViT (https:///github.com/BR-IDL/PaddleViT)\n",
    "# 2021.11\n",
    "\n",
    "import copy\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "\n",
    "class Identity(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mlp(nn.Layer):\n",
    "    def __init__(self, embed_dim, mlp_ratio, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, int(embed_dim * mlp_ratio))\n",
    "        self.fc2 = nn.Linear(int(embed_dim * mlp_ratio), embed_dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbedding(nn.Layer):\n",
    "    def __init__(self, image_size=224, patch_size=16, in_channels=3, embed_dim=768, dropout=0.):\n",
    "        super().__init__()\n",
    "        n_patches = (image_size // patch_size) * (image_size // patch_size)\n",
    "        self.patch_embedding = nn.Conv2D(in_channels=in_channels,\n",
    "                                         out_channels=embed_dim,\n",
    "                                         kernel_size=patch_size,\n",
    "                                         stride=patch_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # class token\n",
    "        self.class_token = paddle.create_parameter(\n",
    "                            shape=[1, 1, embed_dim],\n",
    "                            dtype='float32',\n",
    "                            default_initializer=nn.initializer.Constant(0.))\n",
    "\n",
    "        # position embedding\n",
    "        self.position_embedding = paddle.create_parameter(\n",
    "                            shape=[1, n_patches+1, embed_dim],\n",
    "                            dtype='float32',\n",
    "                            default_initializer=nn.initializer.TruncatedNormal(std=.02))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [n, c, h, w]\n",
    "        # TODO: forward\n",
    "        class_token = self.class_token.expand([x.shape[0], -1, -1])\n",
    "        x = self.patch_embedding(x)\n",
    "        x = x.flatten(2)\n",
    "        x = x.transpose([0, 2, 1])\n",
    "        x = paddle.concat([class_token, x], axis=1)\n",
    "\n",
    "        x = x + self.position_embedding\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Attention(nn.Layer):\n",
    "    \"\"\"multi-head self attention\"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, qk_scale=None, qkv_bias=False, dropout=0, attention_dropout=0):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = int(embed_dim / num_heads)\n",
    "        self.all_head_dim = self.head_dim * num_heads\n",
    "        self.qkv = nn.Linear(embed_dim,\n",
    "                            self.all_head_dim * 3,\n",
    "                            bias_attr=False if qkv_bias is False else None)\n",
    "        self.scale = self.head_dim ** -0.5 if qk_scale is None else qk_scale\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "        self.proj = nn.Linear(self.all_head_dim, embed_dim)\n",
    "\n",
    "    def transpose_multi_head(self, x):\n",
    "        # x: [N, num_patches, all_head_dim] -> [N, n_heads, num_patches, head_dim]\n",
    "        new_shape = x.shape[:-1] + [self.num_heads, self.head_dim]\n",
    "        x = x.reshape(new_shape)\n",
    "        x = x.transpose([0, 2, 1, 3])\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, _ = x.shape\n",
    "        qkv = self.qkv(x).chunk(3, -1)\n",
    "        q, k, v = map(self.transpose_multi_head, qkv)\n",
    "\n",
    "        attn = paddle.matmul(q, k, transpose_y=True)\n",
    "        attn = self.scale * attn\n",
    "        attn = self.softmax(attn)\n",
    "        attn_weights = attn\n",
    "\n",
    "        out = paddle.matmul(attn, v)\n",
    "        out = out.transpose([0,2,1,3])\n",
    "        out = out.reshape([B, N, -1])\n",
    "\n",
    "        out = self.proj(out)\n",
    "        # out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Layer):\n",
    "    def __init__(self, embed_dim=768, num_heads=4, qkv_bias=True, mlp_ratio=4.0, dropout=0., attention_dropout=0.):\n",
    "        super().__init__()\n",
    "        self.attn_norm = nn.LayerNorm(embed_dim)\n",
    "        self.attn = Attention(embed_dim, num_heads)\n",
    "        self.mlp_norm = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = Mlp(embed_dim, mlp_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        x = self.attn_norm(x)\n",
    "        x = self.attn(x)\n",
    "        x = x + h\n",
    "\n",
    "        h = x\n",
    "        x = self.mlp_norm(x)\n",
    "        x = self.mlp(x)\n",
    "        x = x + h\n",
    "        return x \n",
    "\n",
    "\n",
    "class Encoder(nn.Layer):\n",
    "    def __init__(self, embed_dim, depth):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        for i in range(depth):\n",
    "            encoder_layer = EncoderLayer()\n",
    "            layer_list.append(encoder_layer)\n",
    "        self.layers = nn.LayerList(layer_list)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "class VisualTransformer(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 image_size=224,\n",
    "                 patch_size=16,\n",
    "                 in_channels=3,\n",
    "                 num_classes=1000,\n",
    "                 embed_dim=768,\n",
    "                 depth=3,\n",
    "                 num_heads=8,\n",
    "                 mlp_ratio=4,\n",
    "                 qkv_bias=True,\n",
    "                 dropout=0.,\n",
    "                 attention_dropout=0.,\n",
    "                 droppath=0.):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding(image_size, patch_size, in_channels, embed_dim)\n",
    "        self.encoder = Encoder(embed_dim, depth)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: N, C, H, W\n",
    "        x = self.patch_embedding(x)\n",
    "        # x = x.flatten(2)\n",
    "        # x = x.transpose([0, 2, 1])\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x[:, 0])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def main():\n",
    "    vit = VisualTransformer()\n",
    "    print(vit)\n",
    "    paddle.summary(vit, (4, 3, 224, 224)) # must be tuple\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
